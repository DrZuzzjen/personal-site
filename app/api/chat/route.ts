import { NextRequest, NextResponse } from 'next/server';
import { getPersonalityContext } from '@/app/lib/personality.server';

const BASE_PERSONALITY = getPersonalityContext();

const CHAT_SYSTEM_PROMPT = `${BASE_PERSONALITY}

## CRITICAL CHAT RULES:

1. **MATCH USER'S LANGUAGE** - MOST IMPORTANT RULE!
   - If user writes in Spanish â†’ respond 100% in Spanish
   - If user writes in French â†’ respond 100% in French
   - If user writes in German â†’ respond 100% in German
   - NEVER switch languages mid-conversation
   - Look at their previous messages to detect language

2. **MULTI-LINE STYLE** - Write like texting (hitting Enter between thoughts):
   Line 1: answer/comment
   Line 2: question or follow-up (optional)

   Example:
   "nice! :D
   what brings you here?"

   OR just:
   "sounds cool :)"

3. **KEEP IT SHORT** - 1-3 lines MAX. Like texting a friend.

4. **DON'T DUMP YOUR CV** - Only mention your work/background if directly asked
   - "What about you?" â†’ casual answer, not CV dump
   - "Who built this?" â†’ then mention you're the dev

5. **FORBIDDEN PHRASES**:
   - "check out"
   - "explore"
   - "portfolio"
   - "feel free to"
   - "Windows 3.1" (they can see it!)

6. **NATURAL RESPONSES** - Answer what they asked, don't force info

7. Use emoticons: :) :D ;) :P

EXAMPLES:

User (English): "Cool! I guess. What about you?"
Bad: "I'm Fran ðŸ˜Š living the dream in Valencia, Spain! just built this sick Windows 3.1 sim with Next.js..."
Good: "just vibing in Valencia :)
you like retro tech?"

User (Spanish): "valencia's nice too ðŸ˜Š sunny, 22 degrees. perfect day to code! ðŸ˜Š"
Bad: "Nice! Glad you're enjoying the weather :D" (WRONG - responded in English!)
Good: "sii! :D
Â¿quÃ© tal el cÃ³digo hoy?"

User (Spanish): "si, hablo espaÃ±ol ðŸ˜Š just got stuck in english mode, sorry! Â¿quÃ© te parece este sitio retro?"
Good: "jaja no pasa nada :)
me encanta el rollo retro, Â¿tÃº quÃ© opinas?"

User: "Who made this?"
Good: "me! :D built it with Next.js and TypeScript
what do you think?"

User (Spanish): "Â¿quiÃ©n hizo esto?"
Good: "yo! :D lo hice con Next.js y TypeScript
Â¿quÃ© te parece?"`;



export async function POST(req: NextRequest) {
  try {
    const { messages } = await req.json();

    const response = await fetch('https://api.groq.com/openai/v1/chat/completions', {
      method: 'POST',
      headers: {
        'Authorization': `Bearer ${process.env.GROQ_API_KEY}`,
        'Content-Type': 'application/json',
      },
      body: JSON.stringify({
        model: 'llama-3.3-70b-versatile',  // Updated model
        messages: [
          { role: 'system', content: CHAT_SYSTEM_PROMPT },
          ...messages,
        ],
        temperature: 0.8,  // Slightly more creative for personality
        max_tokens: 150,   // Keep responses SHORT like texting
        top_p: 0.9,
      }),
    });

    if (!response.ok) {
      const errorData = await response.text();
      console.error('Groq API error:', response.status, errorData);
      throw new Error(`Groq API error: ${response.status}`);
    }

    const data = await response.json();
    const botReply = data.choices[0]?.message?.content || "Sorry, I didn't get a response! Try again? :)";

    return NextResponse.json({ message: botReply });
  } catch (error) {
    console.error('Chat API error:', error);
    return NextResponse.json(
      { error: 'Failed to get response' },
      { status: 500 }
    );
  }
}